import { GoogleGenerativeAI, Part } from "@google/generative-ai";
import { GoogleAIFileManager } from "@google/generative-ai/server";

const apiKey = process.env.GEMINI_API_KEY || "";
const genAI = new GoogleGenerativeAI(apiKey);
const fileManager = new GoogleAIFileManager(apiKey);

// ãƒ¢ãƒ‡ãƒ«ã¯ gemini-2.5-flashï¼ˆthinking ã¯æœªä½¿ç”¨ï¼‰
const modelName = "gemini-2.5-flash";

// In-memory rate limiter
const requestsMap = new Map<string, number[]>();

export async function POST(req: Request) {
    try {
        // 1. Rate Limiting
        const ip = req.headers.get("x-forwarded-for") ?? "unknown";
        const now = Date.now();
        const windowMs = 60_000;
        const limit = 5;

        const timestamps = (requestsMap.get(ip) ?? []).filter(
            (t) => now - t < windowMs
        );

        if (timestamps.length >= limit) {
            return new Response(
                JSON.stringify({
                    error: "çŸ­æ™‚é–“ã«ã‚¢ã‚¯ã‚»ã‚¹ãŒé›†ä¸­ã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                }),
                {
                    status: 429,
                    headers: { "Content-Type": "application/json" },
                }
            );
        }
        timestamps.push(now);
        requestsMap.set(ip, timestamps);

        // 2. Parse Request
        const { messages } = await req.json() as {
            messages: { role: "user" | "assistant"; content: string }[];
        };

        if (!messages || !Array.isArray(messages) || messages.length === 0) {
            return new Response(JSON.stringify({ error: "Invalid messages format" }), {
                status: 400,
                headers: { "Content-Type": "application/json" },
            });
        }

        const lastUserMessage = messages.slice().reverse().find(m => m.role === 'user');
        const userInputLength = lastUserMessage ? lastUserMessage.content.length : 0;

        // Logging variables
        const start = Date.now();
        let responseText = "";
        let success = false;
        let errorMessage: string | null = null;
        let fileUrisLog = [];

        try {
            // 3. Configure Model
            const model = genAI.getGenerativeModel({
                model: modelName,
            });

            // 4. Retrieve Active Files from Google File API
            const listFilesResponse = await fileManager.listFiles();

            // çŠ¶æ…‹åˆ¥ã«åˆ†é¡
            const SUPPORTED_MIME_TYPES = [
                'text/plain', 'text/html', 'text/css', 'text/javascript', 'application/json', 'text/csv', 'text/markdown',
                'image/jpeg', 'image/png', 'image/webp', 'image/heic', 'image/heif',
                'application/pdf'
            ];

            const activeFiles = listFilesResponse.files.filter(f =>
                f.state === "ACTIVE" &&
                // Officeç³»ãªã©ãŒæ··å…¥ã—ã¦ã„ãŸå ´åˆã€APIã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚é™¤å¤–ã™ã‚‹
                // (æ–°è¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ†ã¯ text/plain ã«å¤‰æ›ã•ã‚Œã¦ã„ã‚‹ãŒã€éå»åˆ†å¯¾ç­–)
                !f.mimeType.includes('officedocument') &&
                !f.mimeType.includes('wordprocessingml') &&
                !f.mimeType.includes('spreadsheetml')
            );
            const processingFiles = listFilesResponse.files.filter(f => f.state === "PROCESSING");
            const failedFiles = listFilesResponse.files.filter(f => f.state === "FAILED");

            // ãƒ­ã‚°ç”¨ã«è¨˜éŒ²
            console.log("[RAG Update] Files Status:", {
                active: activeFiles.length,
                processing: processingFiles.length,
                failed: failedFiles.length
            });

            // ã‚‚ã—å‡¦ç†ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã€ã‹ã¤æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒ1ã¤ã‚‚ãªã„å ´åˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¾…ã£ã¦ã‚‚ã‚‰ã†
            if (activeFiles.length === 0 && processingFiles.length > 0) {
                return new Response(JSON.stringify({
                    reply: "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè³‡æ–™ã‚’AIãŒèª­ã¿è¾¼ã‚“ã§ã„ã‚‹æœ€ä¸­ã§ã™ï¼ˆå‡¦ç†ä¸­ï¼‰ã€‚\næ•°ç§’ã€œ1åˆ†ã»ã©å¾…ã£ã¦ã‹ã‚‰ã€ã‚‚ã†ä¸€åº¦è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚ğŸ¦‰"
                }), {
                    status: 200,
                    headers: { "Content-Type": "application/json" },
                });
            }

            // ãƒ­ã‚°ç”¨ã«ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¨˜éŒ²
            fileUrisLog = activeFiles.map(f => f.displayName || f.name);

            // 5. Construct Contents
            // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ˜ç¤ºçš„ã«è¨­å®š
            const systemInstruction = {
                role: "system",
                parts: [
                    { text: "ã‚ãªãŸã¯è‡ªæ²»ä½“ã®æœ‰èƒ½ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ·»ä»˜ã®è³‡æ–™ç¾¤ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚è³‡æ–™ã«ãªã„æƒ…å ±ã«ã¤ã„ã¦ã¯æ¨æ¸¬ã›ãšã€ã€Œè³‡æ–™ã«ã¯è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚" + (activeFiles.length === 0 ? "\n\nç¾åœ¨ã€å‚ç…§ã§ãã‚‹è³‡æ–™ï¼ˆRAGï¼‰ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€èˆ¬çš„ãªçŸ¥è­˜ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚" : "") }
                ]
            };

            // ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸éƒ¨åˆ†
            const fileParts: Part[] = [];
            for (const file of activeFiles) {
                fileParts.push({
                    fileData: {
                        mimeType: file.mimeType,
                        fileUri: file.uri
                    }
                });
            }

            // å±¥æ­´ã®æ§‹ç¯‰
            const historyContents = messages.map((m) => ({
                role: m.role === "assistant" ? "model" : "user",
                parts: [{ text: m.content } as Part],
            }));

            // ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã€å±¥æ­´ã®å…ˆé ­ï¼ˆæœ€åˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ï¼‰ã«çµ±åˆã™ã‚‹ã‹ã€ç‹¬ç«‹ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æŒ¿å…¥ã™ã‚‹ã€‚
            let contents = [...historyContents];

            if (fileParts.length > 0) {
                const fileContextMessage = {
                    role: "user",
                    parts: [...fileParts, { text: "ã“ã‚Œã‚‰ã®è³‡æ–™ã‚’å‚ç…§ã—ã¦ã€ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚" } as Part]
                };
                // å…ˆé ­ã«è¿½åŠ 
                contents = [fileContextMessage, ...historyContents];
            }

            // 6. Generate Content
            const result = await model.generateContent({
                contents,
                systemInstruction,
                generationConfig: {
                    maxOutputTokens: 1024,
                    temperature: 0.2,
                    topP: 0.95,
                    topK: 40,
                }
            });

            const response = await result.response;
            responseText = response.text();
            success = true;

            return new Response(JSON.stringify({ reply: responseText }), {
                status: 200,
                headers: { "Content-Type": "application/json" },
            });

        } catch (llmError) {
            success = false;
            errorMessage = llmError instanceof Error ? llmError.message : String(llmError);
            console.error("Gemini API Error:", llmError);
            return new Response(JSON.stringify({ error: "Failed to generate content" }), {
                status: 500,
                headers: { "Content-Type": "application/json" },
            });
        } finally {
            const durationMs = Date.now() - start;
            const logObject = {
                timestamp: new Date().toISOString(),
                route: "/api/chat",
                model: modelName,
                userInputLength,
                responseLength: responseText.length,
                durationMs,
                success,
                errorMessage,
                ragType: "google-file-api-dynamic",
                fileCount: fileUrisLog.length,
                thinking: "disabled"
            };
            console.log("[LLM_LOG]", JSON.stringify(logObject));
        }

    } catch (error) {
        console.error("API Route Error:", error);
        return new Response(JSON.stringify({ error: "Internal Server Error" }), {
            status: 500,
            headers: { "Content-Type": "application/json" },
        });
    }
}
